import pandas as pd
import streamlit as st
from streamlit_chat import message
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
import torch
import torch.nn.functional as F
import json
from catboost import CatBoostClassifier
from tensorflow.keras.preprocessing.text import Tokenizer
import pickle
import os
from model_predict import *
import random
import psycopg2
import time
from pyecharts import options as opts
from pyecharts.charts import Bar
from streamlit_echarts import st_echarts


# ê²½ë¡œ ì§€ì •
filePath, fileName = os.path.split(__file__)

# ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
def init_connection():
    return psycopg2.connect(**st.secrets["postgres"])

conn = init_connection()

# ì¿¼ë¦¬ ì‹¤í–‰(ì§€ê¸ˆì€ insert, update, delteë§Œ ê°€ëŠ¥í•˜ê²Œ)
def run_query(query):
    with conn.cursor() as cur:
        cur.execute(query)
        conn.commit()

# í† í¬ë‚˜ì´ì € ë¡œë“œ
@st.cache(allow_output_mutation = True)
def tokenizer_load():
    with open(os.path.join(filePath, 'models', 'tokenizer.pickle'), 'rb') as handle:
        tokenizer = pickle.load(handle)
        return tokenizer
    
# ëª¨ë¸ ë¡œë“œ
@st.cache(allow_output_mutation = True)
def predict_model_load():
    predict_model = CatBoostClassifier()
    predict_model.load_model(os.path.join(filePath, 'models', 'catboost.cbm'))
    return predict_model

@st.cache(allow_output_mutation = True)
def cached_model():
    model = SentenceTransformer('jhgan/ko-sroberta-multitask')
    return model

@st.cache(allow_output_mutation = True)
def get_dataset():
    df = pd.read_parquet(os.path.join(filePath, 'data', 'WellnessData.parquet'), engine='pyarrow')
    add_question_df = pd.read_csv(os.path.join(filePath, 'data', 'chatbot_emotion_Q_list.csv'), encoding = 'cp949')
    # df['embedding'] = df['embedding'].apply(json.loads)
    return df, add_question_df

def main():
    
    # í˜ì´ì§€ ì„¸íŒ…
    st.set_page_config(page_title = "ìŒì•… ì‰¼í‘œ", layout='wide', initial_sidebar_state='collapsed')
    
    # ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
    model = cached_model()
    
    # í† í¬ë‚˜ì´ì €, ì˜ˆì¸¡ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
    tokenizer = tokenizer_load()
    predict_model = predict_model_load()
    
    
    # ë°ì´í„°ì…‹ ë¶ˆëŸ¬ì˜¤ê¸°
    df, add_question_df = get_dataset()

    # st.markdown('## ì§€ê¸ˆ ëŠë¼ëŠ” ê°ì •ë“¤ì„ ì´ì•¼ê¸°í•´ì£¼ì„¸ìš” ğŸ˜Š')
    st.markdown("<h2 style='text-align: center; color: black;'>ì§€ë‚˜ì¹˜ëŠ” ê°ì •ë“¤ê³¼ ì¼ìƒë“¤ì„ ì´ì•¼ê¸°í•´ì£¼ì„¸ìš” ğŸ˜Š</h2>", unsafe_allow_html=True)
    st.write(' ')

    # ë‘ êµ¬ì—­ìœ¼ë¡œ ë‚˜ëˆ”
    visualization, chatbot = st.columns(2)

    with chatbot:
        # ì„¸ì…˜ìŠ¤í…Œì´íŠ¸ì— ì„¸ì…˜ì´ ì¬ì‹¤í–‰ë˜ë„ ì´ˆê¸°í™” ë˜ì§€ ì•Šê²Œë” ì„¸ì…˜ ì„¤ì •
        if 'generated' not in st.session_state:
            st.session_state['generated'] = []
            
        if 'past' not in st.session_state:
            st.session_state['past'] = []

                
        # ì±„íŒ… í¼ ë§Œë“¤ê¸°
        with st.form('form', clear_on_submit = True): # ì œì¶œí•˜ë©´ í…ìŠ¤íŠ¸ ë°•ìŠ¤ ì§€ì›Œì§€ê²Œ ë§Œë“¤ê¸°
            user_input = st.text_input('ê³ ë¯¼í•˜ëŠ” ë‚˜ : ', '')
            submitted = st.form_submit_button('ì „ì†¡')
            
        if submitted and user_input: # ì œì¶œê³¼ user_input ê°’ì´ Trueë©´ ì„ë² ë”©ì„ í†µí•´ ìµœê³  ìœ ì‚¬ë„ ë‹µë³€ ì¶”ì¶œ
            # ëª¨ë¸ ì„ë² ë”©
            embedding = model.encode(user_input)
            
            # ì„ë² ë”© í•œ ê²ƒ ì¤‘ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
            # df['simillarity'] = df['embedding'].apply(lambda x : cosine_similarity([embedding], [x]).squeeze())
            df['simillarity'] = F.cosine_similarity(torch.FloatTensor(embedding * len(df['embedding'])),  torch.FloatTensor(df['embedding']))

            # ê°€ì¥ ìœ ì‚¬í•œ ë‹µë³€ ì¶”ì¶œ
            answer = df.loc[df['simillarity'].idxmax()]
            st.session_state['past'].append(user_input)
            
            # ìœ ì‚¬ë„ ìƒ 0.64 ë¯¸ë§Œì´ë©´ ì§ˆë¬¸ í•˜ëŠ” ì‘ë‹µì§€ë¡œ ë„˜ì–´ê°. 0.64
            if answer['simillarity'] < 0.64:
                
                text_list = ('ì œê°€ ë‹¹ì‹ ì—ê²Œ í˜ì´ ë˜ëŠ” ë¹„ë°€ ì¹œêµ¬ê°€ ë˜ì–´ ë“œë¦´ê²Œìš”.',
                            'êº¼ë‚´ê³  ì‹¶ì€ ë§ˆìŒì„ ì–˜ê¸°í•´ì£¼ë©´ ì œê°€ ì—´ì‹¬íˆ ë“¤ì„ê²Œìš”',
                            'ì§€ê¸ˆ ëŠë¼ì‹œëŠ” ê°ì •ì„ ì¡°ê¸ˆ ë” ì•Œë ¤ì£¼ì„¸ìš”',
                            'ì œê°€ ë‹¹ì‹ ì—ê²Œ í˜ì´ ë˜ëŠ” ë¹„ë°€ ì¹œêµ¬ê°€ ë˜ì–´ ë“œë¦´ê²Œìš”.',
                            'êº¼ë‚´ê³  ì‹¶ì€ ë§ˆìŒì„ ì–˜ê¸°í•´ì£¼ë©´ ì œê°€ ì—´ì‹¬íˆ ë“¤ì„ê²Œìš”',
                            'ì €ëŠ” í•­ìƒ ì—¬ê¸° ìˆì–´ìš”. í•˜ê³  ì‹¶ì€ ì´ì•¼ê¸°ê°€ ìˆë‹¤ë©´ ë“¤ë ¤ì£¼ì‹œê² ì–´ìš”?',
                            'ì €ëŠ” ë“¤ì„ ì¤€ë¹„ê°€ ë˜ì–´ ìˆì–´ìš”.')
                
                text_length = len(text_list) - 1
                text = text_list[random.randint(0, text_length)]
                
                # íŠ¹ì • ìƒí™©ì—ì„œ ë‹µë³€ ë³€ê²½(ë„í¬)
                
                for idx, i in enumerate(add_question_df['chatbot_answer']):
                    if i in answer['A']:
                        text = add_question_df.at[idx,'add_question']
                        break
                st.session_state['generated'].append(text)
                
                # st.session_state['generated'].append('ì§€ê¸ˆ ëŠë¼ì‹œëŠ” ê°ì •ì„ ì¡°ê¸ˆ ë” ì•Œë ¤ì£¼ì„¸ìš”')
                
            else:
                st.session_state['generated'].append(answer['A'])


        for i in range(len(st.session_state['past']) - 1, -1, -1):
            message(st.session_state['past'][i], is_user = True, key = str(i) + '_user', )
            message(st.session_state['generated'][i], key = str(i) + '_bot')
            
    user_text = ' '.join(st.session_state['past'])
    emotion, emotion_proba = predict_value(user_text, predict_model, tokenizer)
    
    with visualization:
        
        # ê°ì •ê²Œì´ì§€
        user_length = len(user_text)
        
        tab1, tab2, tab3 = st.tabs(["ğŸ’–ê°ì • ì¸¡ì •", "ğŸ”ë‚´ ê°ì •ê³¼ ìœ ì‚¬í•œ ê³¡ì„ ë“£ê³  ì‹¶ì–´ìš”", "ğŸ€ë‚´ ê°ì •ê³¼ ë°˜ëŒ€ë˜ëŠ” ê³¡ì„ ë“£ê³  ì‹¶ì–´ìš”"])
        # st.write(user_length / 300)
        
        sql_list = [0] # user_idë¥¼ ë„£ì„ ì˜ˆì •(ì¶”í›„)
                
        # ìµœëŒ€ ê¸€ììˆ˜
        base_len = 100
        
        total_length = int(user_length / base_len * 100)
        if total_length <= 100:
            tab1.markdown('##### ğŸˆ ê°ì •ê²Œì´ì§€')
            progress = tab1.progress(0)
            tab1.markdown('##### ë‹¹ì‹ ì˜ ê°ì •ì´ ì°¨ì˜¤ë¥´ê³  ìˆì–´ìš”!')
            progress.progress(total_length)
        else :
            tab1.markdown('##### ğŸ‰ ì¶©ë¶„í•œ ê°ì •ì´ ì°¼ì–´ìš”! ìƒíƒœë¥¼ í™•ì¸í•´ë³´ì„¸ìš”')
            if tab1.button('ê°ì • ìƒíƒœ í™•ì¸í•˜ê¸°'):
                options = pie_chart(emotion_proba)
                st_echarts(options=options, height="500px")        
                            
        # ë…¸ë˜ ì¶”ì²œ ëˆ„ë¥´ë©´ catboost ëª¨ë¸ ì‘ë™, ì•„ì›ƒí’‹ì€ predict_proba
        # ê¸€ì ìˆ˜ê°€ 100ë³´ë‹¤ í´ ë•Œë§Œ ì¶”ì²œ ë²„íŠ¼ í™œì„±í™”
        if total_length >= 0:
            if tab2.button('ì¶”ì²œğŸ˜Š'):            
                # proba ê°’, ìŒì•… ë„£ê¸°
                for x in emotion_proba.tolist()[0]:
                    sql_list.append(x)
                
                # ì˜ˆì¸¡(ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê¸°ë°˜)
                predict_cosine = cos_recommend(list(emotion_proba))
                
                # sql_listì— ì˜ˆì¸¡ê°’ ë„£ê¸°
                sql_list.extend([predict_cosine[0], ''])
                
                # ë…¸ë˜ ì¶œë ¥
                tab2.write(predict_cosine[0])
                tab2.video('https://www.youtube.com/watch?v=R8axRrFIsFI')
                
                # ì¿¼ë¦¬ ì‹¤í–‰
                sql_query = f"insert into song.user_info (name, emotion0, emotion1, emotion2, emotion3, emotion4, song_sim, song_dif) values ({str(sql_list)[1:-1]});"
                run_query(sql_query)


        # ê¸€ì ìˆ˜ê°€ 100ë³´ë‹¤ í´ ë•Œë§Œ ì¶”ì²œ ë²„íŠ¼ í™œì„±í™”
        if total_length >= 0:
            if tab3.button('ì¶”ì²œğŸ˜†'):
                # proba ê°’, ìŒì•… ë„£ê¸°
                for x in emotion_proba.tolist()[0]:
                    sql_list.append(x)
                
                # ì˜ˆì¸¡(ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê¸°ë°˜)
                predict_cosine = cos_recommend(list(emotion_proba))
                
                # sql_listì— ì˜ˆì¸¡ê°’ ë„£ê¸°
                sql_list.extend(['', predict_cosine[1]])

                # ë…¸ë˜ ì¶œë ¥
                tab3.write(predict_cosine[1])
                tab3.video('https://www.youtube.com/watch?v=R8axRrFIsFI')
                
                # ì¿¼ë¦¬ì‹¤í–‰
                sql_query = f"insert into song.user_info (name, emotion0, emotion1, emotion2, emotion3, emotion4, song_sim, song_dif) values ({str(sql_list)[1:-1]});"
                run_query(sql_query)
            
    # # í…ìŠ¤íŠ¸ ì €ì¥
    # st.write(st.session_state['past'])

if __name__ == "__main__":
    main()